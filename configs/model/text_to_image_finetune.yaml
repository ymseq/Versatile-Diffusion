env:
  experiment_id: "vd_finetune_mydata"
  log_root_dir: "./logs" 
  log_dir: "./logs/vd_finetune_mydata"
  gpu_count: 1
  nodes: 1
  node_rank: 0
  dist_backend: "nccl"
  dist_url: "tcp://127.0.0.1:11233"
  cuda: true
  rnd_seed: 42

model: MODEL(vd_text_to_image)
model_pretrain_path: "/root/vd/pretrained/vd-four-flow-v1-0.pth"

train:
  main:  "lib.utils.train"
  stage: "lib.text_to_image_train_stage.TextToImageTrainStage"

  # ----------------- batch & dataloader -----------------
  batch_size: 1
  batch_size_per_gpu: 1
  dataset_num_workers: 1
  dataset_num_workers_per_gpu: 1

  skip_partial_batch: false

  # ----------------- 训练步数 & 日志 / ckpt -----------------
  step_type: "iter"             # 以迭代数作为 step 计数
  step_num: 100000              # 总共多少个 iter

  log_every: 10         # 或 20，先让你能看到进度
  eval_every: 1000      # 每 1000 iter eval 一次（根据你的速度可调）
  eval_start: 1000      # 可选：避免一开始就 eval
  ckpt_every: 1000      # 你已经是 1000

  
  save_init_model: false         # 保存一份 init.pth（你已经看到那行 log 了）
  gradacc_every: 10             # 梯度累积
  
  max_txt_len: 77

  vd:
    # x：被加噪 / 去噪的分支（这里是“image latent”）
    x_type: "image"
    x_vae:  "image"

    # c：条件分支（这里是“text context”）
    c_type: "text" 
    c_ctx:  "text"

  # ----------------- 数据集配置（配合 MyVDDataset） -----------------
  dataset:
    symbol: "my_vd_dataset"     # 只是一个名字，会出现在 log 目录里
    name:   "my_vd_dataset"     # 你的 get_dataset() 里默认就是这个
    root: "./data/train2"        # 里面要有 images/ 和 meta.jsonl
    meta_file: "meta.jsonl"
    image_size: 256             # MyVDDataset 里用来 Resize / CenterCrop
    sampler: "default_train"    # 我们在 get_sampler() 里支持的名字

  # ----------------- 优化器 -----------------
  optimizer:
    type: "adam"
    args:
      lr: 1.0e-5
      weight_decay: 0.01
      betas: [0.9, 0.999]
  # optimizer:
  #   type: "sgd"
  #   args:
  #     lr: 1.0e-5
  #     momentum: 0.9
  #     weight_decay: 0.0


  # ----------------- 学习率 scheduler -----------------
  scheduler: null
  # scheduler:
  #   type: "constant"            # 对应 @register('constant') 的 constant_scheduler
  #   args:                       # 这里的字段会直接传到 __init__(lr, step)
  #     lr: 1.0e-5                # 常数学习率（和上面的 lr 保持一致就行）
  #     step: 100000              # 和 step_num 对齐（总 iter 数）
      

eval:
  main: "lib.utils.eval"
  stage: "lib.text_to_image_eval_stage.TextToImageEvalStage"
  batch_size: 1
  batch_size_per_gpu: 1
  dataset_num_workers: 1
  dataset_num_workers_per_gpu: 1

  log_display: 100
  log_dir: "./logs/text_to_image_finetune/eval"
  output_result: false

  evaluator:
    name: "avg_loss"
    args:
      pass

  skip_partial_batch: false
  dataset:
    symbol: "my_vd_dataset"     # 只是一个名字，会出现在 log 目录里
    name:   "my_vd_dataset"     # 你的 get_dataset() 里默认就是这个
    root: "./data/eval"        # 里面要有 images/ 和 meta.jsonl
    meta_file: "meta.jsonl"
    image_size: 256
    sampler: "default_train"
